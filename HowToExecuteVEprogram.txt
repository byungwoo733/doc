VEOS:How to execute VE program
Date:18-Jun-2019

This document describes the information regarding the VEOS version 2.1 or
later.


First of all, you have to login your target VH which means Linux/x86 machines
having VEs.

- How to check the number of VE nodes and cores

  $ unset VE_NODE_NUMBER
  $ /opt/nec/ve/bin/uptime | grep Node
  VE Node: 1
  VE Node: 0
           ^this number means VE Node number

  In this case, you can use two VEs, #0 and #1.

  $ /opt/nec/ve/bin/nproc
  VE Node: 1
  8
  VE Node: 0
  8

  In this case, you can use the 8 cores on each VE node.

  (NOTE) You can get the best VE performance when you execute any VE program
         whose number of threads/processes is less than or equal to the number
         of the VE CPU cores because there is no context switching while
         executing the VE program.


- How to check VEOS mode

  VEOS supports 2 operation modes, Normal mode and NUMA mode.
  You can check the mode by /opt/nec/ve/bin/venumainfo command. 

   $ /opt/nec/ve/bin/venumainfo

  In case of Normal mode, venumainfo displays "available: 1 nodes(0)" and
  it displays information of VE as "node 0". 

  In case of NUMA mode, venumainfo displays "available: 2 nodes(0-1)" and
  it displays information of "node 0" (NUMA node 0) and "node 1" (NUMA node 1).


- How to make a VE program

  $ vi hello.c
  $ /opt/nec/ve/bin/ncc hello.c -o hello


- How to run a VE program

  If you want to execute your program on VE Node #0:

   $ /opt/nec/ve/bin/ve_exec -N 0 ./hello

  If you want to execute your program on VE Node #1:

   $ /opt/nec/ve/bin/ve_exec -N 1 ./hello

  Or when you specify the environment variable for the VE Node number, it is
  not necessary to specify the -N option, such as:

   $ export VE_NODE_NUMBER=1
   $ /opt/nec/ve/bin/ve_exec ./hello

  When you install VEOS, binfmt for VE is configured. It is possible to
  execute VE programs without ve_exec. If multiple VE nodes exist, the VE 
  node which executes VE program is specified by environment variable 
  (VE_NODE_NUMBER), such as:

   $ export VE_NODE_NUMBER=1
   $ ./hello

  When you want to change the path which the linker should
  look in to while linking dynamic libraries/shared libraries,
  you can use VE_LD_LIBRARY_PATH which is the predefined environment
  variable in VEOS. For example, if you want to set it to
  "/path/to/user/lib":

   $ export VE_LD_LIBRARY_PATH=/path/to/usr/lib 
   $ /opt/nec/ve/bin/ve_exec ./hello

  Please see 've_exec options' section and 'Environment variables' 
  section for more variables.


- How to run a VE program (NUMA mode)

  When VEOS is running as NUMA mode, you can use VE like NUMA. 

  You execute a program without any NUMA options, then VEOS creates a process 
  for the program on a NUMA node whose load is lower. When the process requests
  memory allocation, memory belonging a local NUMA node on which the process is
  running (local memory) is allocated first. If the local memory is full, memory
  belonging an opposite NUMA node (remote memory) is allocated. 

   $ /opt/nec/ve/bin/ve_exec ./hello
  
  You can use options to specify using NUMA node and memory policy.

   $ /opt/nec/ve/bin/ve_exec --cpunodebind=0 --localmembind ./hello

  You can also use an environment variable for NUMA, VE_NUMA_OPT, to specify
  the options.

   $ export VE_NUMA_OPT="--cpunodebind=0 --localmembind"
   $ /opt/nec/ve/bin/ve_exec ./hello

  Note:
  By default, VEOS allocates local memory first, then it allocates remote
  memory if local memory is full. VEOS defines the policy as MPOL_DEFAULT. 
  When '--localmembind' is specified, VEOS allocates local memory only. VEOS 
  defines the policy as MPOL_BIND.

  Please see 've_exec options' section and 'Environment variables' 
  section for detail.


- How to add path to the default library search path

  Please put a configuration file to specify additional search path into
  "/etc/opt/nec/ve/ld.so.conf.d" directory and then run the following command.

   $ sudo /opt/nec/ve/glibc/sbin/ldconfig

  The name of the configuration file should be end with ".conf" and the list of
  additional search path should be written in it.


- How to enable accelerated I/O

  "Accelerated I/O" is a feature which improves I/O performance by
  efficient data transfer between VE and VH.

  The throughput and the latency of the below read/write family system
  calls will be improved.

      read     write
      pread    pwrite
      readv    writev
      preadv   pwritev

  This feature uses huge pages as buffers, and the same I/O path which
  is used when data is transferred via InfiniBand. Because of this,
  this feature can be enabled when the below requirements are met.

   * The kernel parameter "vm.nr_hugepages" is more than or equal to
     256/per VE
      - Please see sysctl(8) man page to set the kernel parameter

   * VH does't use ScaTeFS
      - Please enable ScaTeFS direct I/O instead of accelerated I/O
        when VH use ScaTeFS

  "Accelerated I/O" is enabled when 'libveaccio' is loaded at
  runtime. Please set environment variable VE_LD_PRELOAD to load it.

   $ export VE_LD_PRELOAD=libveaccio.so.1
   $ ./hello

  Please note data is transferred every 8MB when "Accelerated I/O" is
  enabled. So, read/write family system calls will not be atomic when
  the size is more than 8MB.


- ve_exec options

  ve_exec command accepts the following options.

    -V, --version                 output version information and exit
    -h, --help                    display this help and exit
    -N node, --node=<node>        where node is the VE Node number
                                  on which VE program belongs
    -c core, --core=<core>        where core is the VE core number on
                                  which VE program to be executed
                                  Can't specify both '-c' and '--cpunodebind'
    --                            End of options (Requires if binary name
                                    starts with ‘-’)
  
  NUMA mode only:
    --cpunodebind=<NUMA node ID>  Specify NUMA node ID on which VE program
                                  to be executed
    --localmembind                Only local memory can be allocated.
                                  (MPOL_BIND)
    

- Environment Variables

  These environment variables can control VE program execution.

  * VE_NODE_NUMBER
    It specifies VE node number on which a program will be executed. 

  * VE_LD_LIBRARY_PATH
    This environment variable provides a library path for finding dynamic 
    libraries in colon separated format.

  * VE_LD_PRELOAD
    This environment variable sets the pre-loading path for dynamic linker 
    and that allows to load you specified, shared library before all 
    other shared libraries which are linked to an executable get loaded.
    
  * VE_ATOMIC_IO
    When this environment variable is set to 1, atomic I/O is enabled.
    When VE program invokes one of read/write family system calls and
    send/recv familiy system calls, a buffer is allocated at VH
    side. If atomic I/O is enabled, this buffer's size will the
    request size up to 2GB.

    Enabling atomic I/O has a impact on the below system calls.

      read     write
      pread    pwrite
      readv    writev
      preadv   pwritev
      send     recv
      sendto   recvfrom

    If atomic I/O is not enabled, the buffer size is fixed to 64MB.
    If the requested size is more than 64MB, data will be transferred
    every 64MB. So, read/write family system calls and send/recv
    family system calls will not be atomic in this case.

  * VE_NUMA_OPT
    It specifies NUMA options, "--cpunodebind" and "--localmembind".
    If NUMA options specified by both of VE_NUMA_OPT and a command line 
    argument are specified, VEOS uses a value specified by a command line 
    argument.


- How to run ported commands for VEOS

  If you want to execute your target command, such as ps, on VE Node #0:

   $ export VE_NODE_NUMBER=0
   $ /opt/nec/ve/bin/ps

  If you want to execute your target command, such as ps, on VE Node #1:

   $ export VE_NODE_NUMBER=1
   $ /opt/nec/ve/bin/ps
  
  VEOS supports the following commands which stored in /opt/nec/ve/bin:

   aclocal
   aclocal-1.13
   autoconf
   autoheader
   autom4te
   automake
   automake-1.13
   autoreconf
   autoscan
   autoupdate
   free
   gdb
   ifnames
   iostat
   ipcs
   ipcrm
   libtool
   libtoolize
   lscpu
   lslocks
   mpstat
   pidstat
   pmap
   prlimit
   prtstat
   ps
   sadf
   sar
   strace
   strace-log-merge
   taskset
   time
   tload
   top
   uptime
   ve_exec
   venumainfo
   vmstat
   w

  glibc supports the following commands:

   /opt/nec/ve/glibc/sbin/ldconfig
   /opt/nec/ve/glibc/sbin/ldd


- How to debug VE program
 
  You can use gdb:

   $ export VE_NODE_NUMBER=0
   $ /opt/nec/ve/bin/gdb ./hello
   (gdb) run


- Different points between VEOS and Linux

  Please see the following documents:

  - Difference_Point_System_Calls.pdf
  - Difference_Points_GDB.htm
  - Difference_Points_Commands.pdf
  - Difference_Points_glibc.htm

- VEOS high level design

  Please see the following documents

  - VEOS_high_level_desing.pdf


- When you face VEOS problems

  Please provide the following information in order to analyze the problem.

    1. Version of RPM packages and the kernel
       Please execute the following command to create list of versions
       and provide it.
  
        $ rpm -qa --qf '%{VENDOR} %{NAME}-%{VERSION}-%{RELEASE}.%{ARCH}\n' \
           | grep NEC > version.txt
        $ uname -r >> version.txt
   
    2. Log files
       Please provide the following files.
  
        /var/log/messages*
        /var/opt/nec/ve/veos/*.log.*
        /var/opt/nec/ve/veos/core.* (if exists)
  
  If your facing problem is like freeze of VE process, please provide
  the following information, too. "gdb" package is required to get the
  information.

    3. Core files of VEOS
       Please execute the following command as root to generate core files.
       core.xxxxx (xxxxx is pid) will be created and compressed to
       core.xxxxx.gz. The size of core file will be large though it
       will be compressed. So, enough space is temporarily required in
       the current directory.
       Please provide the compressed core files.
  
        $ pgrep veos | while read pid; do gcore $pid; gzip core.$pid; done


- How to gather debug log of VEOS
  If your facing problem is reproducible, the following debug logs 
  are really helpful to analyze the problem.

  Please edit the configuration file setting log level to "DEBUG" and
  layout to "ve_debug" for all components as follows. 

   $ sudo cp /etc/opt/nec/ve/veos/log4crc /etc/opt/nec/ve/veos/log4crc.org
   $ sudo sed -i -e 's/INFO/DEBUG/g' -e 's/CRIT/DEBUG/g' \
      -e 's/layout="ve"/layout="ve_debug"/g' /etc/opt/nec/ve/veos/log4crc

  And, please reboot VEOS. 

   $ sudo systemctl restart 've-os-launcher@*'

  Please set the following environment variable to specify the directory
  and enable log output. 

   $ export LOG4C_RCPATH=/etc/opt/nec/ve/veos

  Then, please reproduce the issue again and you'll find log files of
  ve_exec at the current directory. 

   ./ve_exec.log.*

  Please gather log files for veos at the following path as default. 

   /var/log/messages*
   /var/opt/nec/ve/veos/*.log.*
   /var/opt/nec/ve/veos/core.* (if exists)

  Last of all, please restore the original log level and reboot VEOS.

   $ sudo cp /etc/opt/nec/ve/veos/log4crc.org /etc/opt/nec/ve/veos/log4crc
   $ sudo systemctl restart 've-os-launcher@*'
   $ unset LOG4C_RCPATH
